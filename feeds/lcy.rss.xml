<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>upperli</title><link>/</link><description></description><atom:link href="/feeds%5Clcy.rss.xml" rel="self"></atom:link><lastBuildDate>Sun, 02 Nov 2014 10:20:00 -0500</lastBuildDate><item><title>推荐系统中的矩阵分解技术（译）</title><link>/blog/recommendation001</link><description>&lt;h6&gt;Yehuda Koren,  Yahoo Research ；&lt;/h6&gt;
&lt;h6&gt;Robert Bell and Chris Volinsky,  AT&amp;amp;T Labs—Research&lt;/h6&gt;
&lt;h6&gt;LCY（译）&lt;/h6&gt;
&lt;blockquote&gt;
&lt;p&gt;正如 Netflix Prize 比赛所证明的，矩阵分解模型在产品推荐方面优于传统的基于邻域的方法，这种模型允许结合像隐式反馈，时间影响和置信水平等额外的信息。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当代消费者面临着过量的选择。电子零售商和供应商提供了大量的产品选择，以及前所未有的机会来满足各种不同的需求和喜好。在消费者和最恰当的产品之间牵桥搭线是提高用户满意度和忠诚度的关键。因此，越来越多的零售商开始对&lt;strong&gt;推荐系统&lt;/strong&gt;感兴趣，这种系统能分析用户在产品中的兴趣来提供个性化的满足用户喜好的推荐。因为好的推荐系统能让用户体验上升一个层次，推荐系统已经成了像 Amazon.com 和 Netflix 等电子商务大佬网站中非常重要的一部分。&lt;/p&gt;
&lt;p&gt;推荐系统对于娱乐产品像如电影，音乐和电视节目等的效果格外显著。许多消费者会观看相同的电影，每个消费者也可能去观看许多不同的电影。已经证明消费者愿意表明自己对电影的满意程度，所以哪个用户喜欢哪部电影这样的数据是大量的并且是可获得的。公司可以分析这些数据来给特定的用户推荐电影。&lt;/p&gt;
&lt;h2&gt;推荐系统策略&lt;/h2&gt;
&lt;p&gt;广泛的讲，推荐系统主要基于两种策略之一。&lt;strong&gt;内容过滤&lt;/strong&gt;方法为每个用户或者产品创建一个配置文件来描述它的本质。举个例子来说，一个电影的配置文件可能包含它的类型，参与演员，票房等等属性。用户的配置文件可能包含户口资料信息或者对于恰当问卷的调查信息。这些配置文件允许程序将用户和产片关联起来。当然，基于内容的策略需要集成的表面信息可能不那么容易收集甚至不可获得。&lt;/p&gt;
&lt;p&gt;一个成功的内容过滤的案例是著名的 Music Genome Project ，这个项目被用于 Pandora.com 的网络音频服务。一个训练有素的音乐分析师为 Music Genome Project 上的每首歌曲的数以百计的显著音乐特征打分。这些属性不仅是一首歌的音乐特性，而且还是和理解听者音乐喜好的有重大联系的特征品质。&lt;/p&gt;
&lt;p&gt;相对于内容过滤的另一种可选择的方式是依赖用户的过去的行为，如以前的交易或者产品打分，这样就不需要创建明确的配置文件。这种方式被称作&lt;strong&gt;协同过滤&lt;/strong&gt; ---由第一个推荐系统的开发人员命名的术语。协同过滤分析用户和产品互赖之间的关系来确定新的用户--产品关联。&lt;/p&gt;
&lt;p&gt;协同过滤算法的一个主要的吸引力是它在域间的开放，它能解决使用内容过滤通常难于理解和描述的数据问题。在比基于内容的技术更加精确的同时，协同过滤算法也有自己的问题，那就是&lt;strong&gt;冷启动&lt;/strong&gt;问题，因为它对系统的新产品和新用户无能为力。从这个角度讲，内容过滤要更胜一筹。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Figure1" src="http://ww3.sinaimg.cn/large/ace0c3edgw1elr7g4npjkj20ar0b3wfp.jpg" /&gt;图一&lt;/p&gt;
&lt;p&gt;协同过滤算法的两个基本领域是基于邻域的方法和隐语义模型。基于邻域的方法专注于计算物品间的或者用户间的关系之一。面向物品的方法基于相同用户对邻居物品的发奋来导出用户对某个物品的喜好。一个产品的邻居是对于同一用户会获得相似打分的物品。例如，《拯救大兵瑞恩》的邻居可能其他电影中包含战争电影，&lt;em&gt;斯皮尔伯格&lt;/em&gt;的电影和&lt;em&gt;汤姆·汉克斯&lt;/em&gt;的电影。为了预测一个特定用户对《拯救大兵瑞恩》的评分，我们可能要这个用户对查看最邻近电影的实际打分。正如图1所示，面向用户的方法识别思维类似的用户来互相完成他人的评分。&lt;/p&gt;
&lt;p&gt;隐语义模型是另一种方法，它试图通过同时解释物品和用户的特征来给物品打分，这些特征应当是从以往评分中推断出来的20到100个因素。在某种意义上，这些因素构成一个计算系统来代替人工的歌曲分析。对于电影来说，已知的因素可以被显而易见的维度测量，例如喜剧对应话剧，演员的数量，亦或是面向儿童的；不好定义的方面像个性的发展和离奇的程度，或者完全无法描述的维度。对于用户来说，每个方面衡量用户在相应电影因素上的感冒程度。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alt Figure2" src="http://ww4.sinaimg.cn/large/ace0c3edgw1elr7i7nlxhj20e00ch75l.jpg" /&gt;图二&lt;/p&gt;
&lt;p&gt;图二用一个简单地两个维度上的例子阐明了这个观点。考虑两个假设的维度：面向女性的对应面向男性的和严肃的对应荒诞的。对于这个模型，一个用户对一部电影的评分预测，和电影的平均得分有关，它等于电影和用户在图上位置的点乘。举个例子来说，我们会预测&lt;em&gt;Gus&lt;/em&gt;喜欢《阿呆和阿瓜》，讨厌《紫颜色》，对《勇敢的心》兴致平平。值得注意的是，许多电影如《11罗汉》和用户例如&lt;em&gt;Dave&lt;/em&gt;将会在这两个维度上表现的十分中性化。&lt;/p&gt;
&lt;h2&gt;矩阵分解方法&lt;/h2&gt;
&lt;p&gt;许多隐语义模型得成功实现都是基于矩阵分解。在矩阵分解的基本形式中，它通过商品的评级模式中推断出影响因素向量，同时描述了物品和用户的属性。物品和用户间的高度对应关系推导出推荐。这种在预测准确的基础上有结合了扩展性的方法今年来变得越来越流行。除此之外，它为现实生活的建模提供了更多的灵活性。&lt;/p&gt;
&lt;p&gt;推荐系统依赖于不同种类的输入数据，这些数据一般存放于一个两个维度分别表示物品和用户的矩阵中。最方便的数据是高质量的&lt;strong&gt;显示反馈&lt;/strong&gt;，这种反馈包括用户对产品兴趣的显式输入。举例来说，Netflix 收集对电影的星级评价，TiVo 的用户通过点击赞成或者反对来表明他们的喜好。我们将显式的用户反馈称作为&lt;strong&gt;评级（ratings）&lt;/strong&gt;。通常来说，显式反馈是一个稀疏矩阵，因为所有的单个用户只对很小一部分物品进行了评价。&lt;/p&gt;
&lt;p&gt;矩阵分解的一个优势是它能结合额外的信息。当显式反馈不可获取时，推荐系统能从隐式反馈中推断用户的喜好，这些信息通过分析用户行为例如购物历史，浏览记录，搜索记录，甚至是鼠标的移动来得出。隐式反馈通常得出一个事件存不存在，所以它被典型的表示为一个密集矩阵。&lt;/p&gt;
&lt;h2&gt;一个基本的矩阵分解模型&lt;/h2&gt;
&lt;p&gt;矩阵分解模型同时将用户和物品映射到  &lt;em&gt;$f$&lt;/em&gt;  维的隐语义空间节点，这样用户--物品的相互作用被建模为产品间的关系。因此，每一个物品$i$都和一个向量 $q_i \in \mathbb{R}^f$ 关联,每个用户$u$都和一个向量 $q_u \in \mathbb{R}^f$ 关联。对于一个给定的物品$i$，元素 $q_i$ 表示物品在每个因素上的相关程度，可以为正或者负。对于一个给定的用户 $u$ ，元素 $q_u$表示用户在对应物品因素上的感兴趣程度，也可以为正数或者负数。点乘结果 $q_i^Tp_u$ , 产生自用户 $u$ 和物品 $i$ 的相互作用,表示用户对物品整体的感兴趣程度，约等于用户对物品的评分，用 $r_{ui}$ 表示，推导出如下公式：$$\hat{r}_{ui} = q_i^Tp_u        \qquad  (1)$$ 困难之处在于如何把每个用户和物品映射到系数向量 $q_i,p_u \in \mathbb{R}^f $上。推荐系统计算完这种映射之后，它就能轻而易举的根据公式（1）来推断用户给任意物品的打分。&lt;/p&gt;
&lt;p&gt;这个模型和&lt;strong&gt;奇异值分解（SVD）&lt;/strong&gt;密切相关，SVD是在信息检索中识别隐式语义因素的比较成熟的技术。在协同过滤领域中应用它需要分解用户--物品评分矩阵。矩阵的稀疏导致大部分值得缺失让这个过程变得非常困难。传统的SVD并没有定义当矩阵不完整的时候应当怎么做。此外，只对一小部分已知实体进行粗泛的处理容易造成过度拟合。&lt;/p&gt;
&lt;p&gt;早期的系统依赖于设算（imputation）来填充未知的评分使得矩阵变得稠密。然而，这种方法在数据量大的时候代价非常高，而且错误的设算会让数据扭曲。因此，近期的研究都建议模型直接只使用一致的数据。为了获取系数向量（ $p_u$ 和 $q_i$ ），应当在已知数据的集合上最小化如下的正规化的方差公式：
$$ \min _{q^*,p^*} \sum _{(u,i) \in \kappa} (r_{ui} - q_i^Tp_u)^2 + \lambda( \left \| q_i \right \|^2+ \left \| p_u \right \|^2) \qquad (2) $$
这里的$\kappa$是已知的$r_{ui}$（训练集）上，$(u,i)$对的集合。&lt;/p&gt;
&lt;p&gt;系统通过拟合先前已知的评分来训练出模型。而目标是推广先前的数据来预测未来的未知的数据。因此，系统应当通过调整来学习参数来避免在已知数据上的过度拟合，它的大小受到约束。常数$\lambda$控制正规化的程度，它通常通过交叉验证法来决定取值。&lt;em&gt;Ruslan Salakhutdinov&lt;/em&gt;和&lt;em&gt;Andriy Mnih&lt;/em&gt;的《Probabilistic Matrix Factorization》为正规化提供了概率基础。&lt;/p&gt;
&lt;h2&gt;学习算法&lt;/h2&gt;
&lt;p&gt;有两种方法来最小化公式（2），&lt;strong&gt;随机梯度下降&lt;/strong&gt;和&lt;strong&gt;交替最小二乘法（ALS）&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;随机梯度下降法&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Simon Funk&lt;/em&gt;普及了公式（2）的梯度下降最优化问题（http://sifter.org/~simon/
journal/20061211.html）在这个算法中遍历训练集中的所有数据。对于每一个训练样例，系统预测 $r_{ui}$ 并且计算预测误差：$$e_{ui} \overset{def}{=} r_{ui} - q_i^Tp_u$$.&lt;/p&gt;
&lt;p&gt;然后它在向梯度的反方向按照$\gamma$的比例大小来调整参数，产生：
&lt;em&gt;$q_i \leftarrow q_u +\gamma \cdot(e_{ui}\cdot p_u-\lamdba \cdot q_i)$
&lt;/em&gt;$p_u \leftarrow p_u +\gamma \cdot(e_{ui}\cdotp_u-\gamma \cdot q_i - \lambda \cdot p_u)$&lt;/p&gt;
&lt;p&gt;这种方法既容易实现又速度快，但是在许多情况下，最好还是使用ALS。&lt;/p&gt;
&lt;h3&gt;交替最小二乘法&lt;/h3&gt;
&lt;p&gt;因为$q_i$和$p_u$都是未知的，所以公式（2）不是凸的。然而，如果我们固定其中一个未知数，优化问题就变成可以很好解决的二次方程。因此，ALS技术轮流固定$p_u$和$q_i$的值。如果$p_u$是固定的系统通过最小二乘法验算$q_i$的值，反之亦然。这保证了每一步公式（2）都会减小知道收敛。&lt;/p&gt;
&lt;p&gt;虽然通常随机梯度下降比ALS简单快速，但是ALS在至少两个方面是有利的。第一点是当系统能使用并行运算时。在ALS算法中，系统计算每个$q_i$的值是独立于其他物品的，计算$p_u$时也相互独立。这就让算法有并行运算的巨大潜力。第二点是当系统致力于隐式数据时。因为训练集不能被看做稀疏的，像梯度下降一样一次循环遍历每条数据是不实际的。ALS能有效的解决这种情况。&lt;/p&gt;
&lt;h2&gt;增加偏差量&lt;/h2&gt;
&lt;p&gt;协同过滤的矩阵分解方法的一大优势是在处理不同数据方面和应用特定数据需求的灵活性。这需要借助于公式（1）并在相同的学习框架下。公式（1）试图找到用户和物品的相互作用关系来产生不同的打分值。然而，分值许多在用户或物品的影响作用下大差异，独立于任何交互，被称作&lt;strong&gt;偏差值（biases）&lt;/strong&gt;或&lt;strong&gt;截距（intercepts）&lt;/strong&gt;。举例来说，典型的协同过滤数据表现出大量的系统倾向，许多用户的打分高于其他人，并且许多电影的评分高于其他电影。毕竟，许多物品被普遍的认为好于其他的。&lt;/p&gt;
&lt;p&gt;因此，将整个分值都用形如 $q_i^Tp_u$ 的相互作用来解释是不够明智的。取而代之的是，系统试图确定个体用户和物品的偏差这部分值，使其能被系统解释，让它从属于真正相互作用的那部分来进行因素建模。加入到$r_{ui}$的一阶偏差形如：$$b_{ui}=\mu+b_i+b_u\qquad(3)$$&lt;/p&gt;
&lt;p&gt;在$r_{ui}$中的偏差值被表示作$b_{ui}$，并且受用户和物品的影响。全局平均值被表示为$\mu$，参数$b_u$和$b_i$分别表示用户u和物品i相对于平均值的差异。举例来说，假设你想要计算用户 Joe 对电影 《泰坦尼克号》的一阶估计，假设多有电影的平均评分$\mu$是3.7星。此外，《泰坦尼克号》比平均水平的电影要好，所以比平均值高0.5星。另一方面，Joe是一个挑剔的用户，他打分比平均打分要低0.3分。因此，Joe 对《泰坦尼克号》的估计值是3.9星（3.7+0.5-0.3）。公式（1）扩展了偏差值后变成：$$\hat{r}_{ui}=\mu+b_i+b_u+q_i^tp_u \qquad (4)$$&lt;/p&gt;
&lt;p&gt;到这里，评分被分解成了四部分：全局平均值，物品偏差，用户偏差，和用户--物品相互作用。这就允许各个部分只解释和它相关的那部分。系统通过最小化如下方差函数来进行学习：$$\min _{p^*,q^*,b^*} \sum _{(u,i) \in \kappa} (r_{ui} - \mu - b_i - b_u - p_uTq_i)^2 + \lambda(\left \| q_i \right \|^2+ \left \| p_u \right \|^2 + b_u^2 + b_i^2)\qquad(5)$$&lt;/p&gt;
&lt;p&gt;因为偏差趋向于捕获许多观察到的信号，其精确建模时至关重要的。因此，有研究提出了更复杂的偏差模型。&lt;/p&gt;
&lt;h2&gt;额外的输入来源&lt;/h2&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">LCY</dc:creator><pubDate>Sun, 02 Nov 2014 10:20:00 -0500</pubDate><guid>tag:,2014-11-02:blog/recommendation001</guid><category>推荐算法  机器学习</category></item></channel></rss>